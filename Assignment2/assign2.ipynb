{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecaed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1e0ad8",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7239d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/forestCover.csv', index_col='Observation_ID', na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c50dfb",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69228eff",
   "metadata": {},
   "source": [
    "## Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a468a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_tree = df.copy()\n",
    "\n",
    "# Drop observations with missing values as they only make up 0.05% of observations\n",
    "df_tree.dropna(inplace=True)\n",
    "\n",
    "# Change Soil_Type1 from categorical to numeric so SMOTE can be applied\n",
    "df_tree['Soil_Type1'] = df_tree['Soil_Type1'].map({ 'positive': 0, 'negative': 1 })\n",
    "\n",
    "X = df_tree.drop('Cover_Type', axis = 1)\n",
    "y = df_tree['Cover_Type']\n",
    "\n",
    "X_train, X_test_tree, y_train, y_test_tree = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f692a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "tree_resampler = SMOTE(random_state=42)\n",
    "\n",
    "X_train_tree, y_train_tree = tree_resampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1873cbe",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c68115b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_knn = df.copy()\n",
    "\n",
    "# Drop observations with missing values as they only make up 0.05% of observations\n",
    "df_knn.dropna(inplace=True)\n",
    "\n",
    "# Change Soil_Type1 from categorical to numeric so SMOTETomek can be applied\n",
    "df_knn['Soil_Type1'] = df_knn['Soil_Type1'].map({ 'positive': 0, 'negative': 1 })\n",
    "\n",
    "# Transform to reduce extreme skewness\n",
    "df_knn['Horizontal_Distance_To_Hydrology'] = np.log1p(df_knn['Horizontal_Distance_To_Hydrology'])\n",
    "\n",
    "X = df_knn.drop('Cover_Type', axis = 1)\n",
    "y = df_knn['Cover_Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c58aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facet & Aspect Correlation : 0.99999805373707\n"
     ]
    }
   ],
   "source": [
    "corr = df_knn['Facet'].corr(df_knn['Aspect'])\n",
    "\n",
    "print(f'Facet & Aspect Correlation : {corr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c90f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facet & Cover_Type Correlation : 0.01707189190902871\n",
      "Aspet & Cover_Type Correlaton : 0.017068499402923768\n"
     ]
    }
   ],
   "source": [
    "corr = df_knn['Facet'].corr(df_knn['Cover_Type'])\n",
    "print(f'Facet & Cover_Type Correlation : {corr}')\n",
    "\n",
    "corr = df_knn['Aspect'].corr(df_knn['Cover_Type'])\n",
    "print(f'Aspet & Cover_Type Correlaton : {corr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf601b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['Aspect', 'Inclination'], inplace=True)\n",
    "X_test.drop(columns=['Aspect', 'Inclination'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a5c2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a9bd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# RobustScaler uses statistics resilient to outliers to scale data\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "330cca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_resampler = SMOTE(random_state=42)\n",
    "\n",
    "X_resampled_np, y_resampled_np = knn_resampler.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bdba923",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_knn = pd.DataFrame(data=X_resampled_np, columns=knn_columns)\n",
    "y_train_knn = pd.Series(y_resampled_np)\n",
    "\n",
    "X_test_knn = pd.DataFrame(data=X_test_scaled, columns=knn_columns)\n",
    "y_test_knn = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2567de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the one-hot encoded columns because SMOTE assumes they are continuous when generating synthetic data\n",
    "one_hot_columns = [col for col in X_train_knn.columns if 'Soil_Type' in col or 'Wilderness_Area' in col]\n",
    "X_train_knn[one_hot_columns] = X_train_knn[one_hot_columns].round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f553fce",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a90c8a",
   "metadata": {},
   "source": [
    "## Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f29307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:\n",
      "{'criterion': 'entropy', 'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Best CV accuracy score:\n",
      "0.9614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_gid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt_classifier,\n",
    "    param_grid=param_gid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    scoring='f1_macro'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "print('Best hyperparameters found:')\n",
    "print(grid_search.best_params_)\n",
    "print('\\nBest CV accuracy score:')\n",
    "print(f'{grid_search.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9afe32bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set Accuracy: 0.9372\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.94      0.94     42349\n",
      "           2       0.95      0.94      0.95     56629\n",
      "           3       0.91      0.92      0.92      7147\n",
      "           4       0.81      0.85      0.83       549\n",
      "           5       0.75      0.85      0.80      1898\n",
      "           6       0.84      0.87      0.86      3471\n",
      "           7       0.93      0.96      0.95      4100\n",
      "\n",
      "    accuracy                           0.94    116143\n",
      "   macro avg       0.88      0.91      0.89    116143\n",
      "weighted avg       0.94      0.94      0.94    116143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "y_pred_tree = best_tree.predict(X_test_tree)\n",
    "\n",
    "test_acc = accuracy_score(y_test_tree, y_pred_tree)\n",
    "\n",
    "print(f\"Test set Accuracy: {test_acc:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_tree, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1060a5",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f35353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['minkowski', 'euclidean']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    scoring='f1_macro'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_knn, y_train_knn)\n",
    "\n",
    "print('Best hyperparameters found:')\n",
    "print(grid_search.best_params_)\n",
    "print('\\nBest CV accuracy score:')\n",
    "print(f'{grid_search.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94562425",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "y_pred_knn = best_tree.predict(X_test_knn)\n",
    "\n",
    "test_acc = accuracy_score(y_test_knn, y_pred_knn)\n",
    "\n",
    "print(f\"Test set Accuracy: {test_acc:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_knn, y_pred_knn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
